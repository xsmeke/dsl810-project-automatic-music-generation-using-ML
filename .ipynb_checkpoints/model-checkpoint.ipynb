{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library for understanding music\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: schubert/schubert_D850_1.mid\n",
      "Loading Music File: schubert/schubert_D850_2.mid\n",
      "Loading Music File: schubert/schubert_D850_3.mid\n",
      "Loading Music File: schubert/schubert_D850_4.mid\n",
      "Loading Music File: schubert/schubert_D935_1.mid\n",
      "Loading Music File: schubert/schubert_D935_2.mid\n",
      "Loading Music File: schubert/schubert_D935_3.mid\n",
      "Loading Music File: schubert/schubert_D935_4.mid\n",
      "Loading Music File: schubert/schub_d760_1.mid\n",
      "Loading Music File: schubert/schub_d760_2.mid\n",
      "Loading Music File: schubert/schub_d760_3.mid\n",
      "Loading Music File: schubert/schub_d760_4.mid\n",
      "Loading Music File: schubert/schub_d960_1.mid\n",
      "Loading Music File: schubert/schub_d960_2.mid\n",
      "Loading Music File: schubert/schub_d960_3.mid\n",
      "Loading Music File: schubert/schub_d960_4.mid\n",
      "Loading Music File: schubert/schuim-1.mid\n",
      "Loading Music File: schubert/schuim-2.mid\n",
      "Loading Music File: schubert/schuim-3.mid\n",
      "Loading Music File: schubert/schuim-4.mid\n",
      "Loading Music File: schubert/schumm-1.mid\n",
      "Loading Music File: schubert/schumm-2.mid\n",
      "Loading Music File: schubert/schumm-3.mid\n",
      "Loading Music File: schubert/schumm-4.mid\n",
      "Loading Music File: schubert/schumm-5.mid\n",
      "Loading Music File: schubert/schumm-6.mid\n",
      "Loading Music File: schubert/schu_143_1.mid\n",
      "Loading Music File: schubert/schu_143_2.mid\n",
      "Loading Music File: schubert/schu_143_3.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ayush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='schubert/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([187.,  41.,  26.,  11.,   6.,   9.,  12.,   6.,   3.,   3.]),\n",
       " array([1.0000e+00, 1.4790e+02, 2.9480e+02, 4.4170e+02, 5.8860e+02,\n",
       "        7.3550e+02, 8.8240e+02, 1.0293e+03, 1.1762e+03, 1.3231e+03,\n",
       "        1.4700e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAJdCAYAAABDKhHGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAABYlAAAWJQFJUiTwAAAnaUlEQVR4nO3df5xtVX0f/M9XUVQSUKypJm0DpKhUo8YbRTABxMZHY2rwCSY20aKNRvsYFaOJJv7oNT8ajMQfUR9NlIiRtERIxScRjan8VExVKPLYEAHhqhgUEQX5IQqs/rH3hHHunJm5lzNzZs56v1+v81pz1l5r77UXdw6f2Wf/qNZaAADow11mPQAAADaO8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEf2mPUANouquiLJ3kl2zHgoAACr2S/J9a21/Xe1o/B3h73vec977nvQQQftO+uBAACs5OKLL87NN9+8W32FvzvsOOigg/Y9//zzZz0OAIAVbdu2LRdccMGO3enrnD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBH9pj1AHqz3ys+OOshTM2O45486yEAALvIkT8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHZlK+Kuqo6vqLVV1blVdX1Wtqk6a0PbEcflKr48u6fOsVdo/fxr7AQAw7/aY0npeleThSW5IcmWSB6/Q9rQkOyYse2aSA5J8aMLyDyS5cJn6T69hjAAA3ZtW+HtJhtB3WZLDk5w5qWFr7bQMAfB7VNW9k/xGku8kOXFC99Naa5OWAQCwiqmEv9baP4W9qtrd1TwzyT2TnNxau2Ya4wIA4HtN68jfNDx3LP9khTaPqKpjk9wjyZeTnNlau3K9BwYAMC82RfirqkOS/GiSSxYfRVzGi5e8v62q3pXk2Nbat9e4rfMnLFrpPEUAgLmwWW718itj+c4Jy69I8sIkD0qyV5IfTPLzGS4ceV6SP13n8QEAzIWZH/mrqn0yBLmJF3q01s5OcvaiqpuSnFJVf5fkM0n+fVW9rrX2mdW211rbNmEc5yd55K6NHgBga9kMR/6ekeReSf77rl7o0Vr7UpLTx7eHTXtgAADzZjOEv4ULPf54N/t/bSz3msJYAADm2kzDX1UdnOHm0Je01s7azdUcPJaXT2VQAABzbNZH/hYu9Fjp9i6pqp9cpq6q6jeTHJLkmiQfnv7wAADmy1Qu+Kiqo5IcNb69/1geUlUnjj9f01p72ZI+eyf5hQwXerxnlU2cU1WXJPlUhvv77ZPksUkemuHij19qrV1/5/YCAGD+Tetq30ckOWZJ3QHjK0m+kORlS5b/Uobz9NbyRI/jkzw6yZFJ9k1ye5IvJnlbkje01nzlCwCwBtN6vNv2JNt3sc/bk7x9jW1/fddHBQDAUrM+5w8AgA0k/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR6YS/qrq6Kp6S1WdW1XXV1WrqpMmtN1vXD7pdfIK2zmmqj5ZVTdU1XVVdVZV/cw09gEAoAd7TGk9r0ry8CQ3JLkyyYPX0OczSU5bpv6zyzWuquOTvHRc/zuT3D3J05P8VVW9sLX21l0fNgBAX6YV/l6SIZRdluTwJGeuoc+FrbXta1l5VR2aIfh9PsmjWmvfGOtfn+T8JMdX1V+31nbs+tABAPoxla99W2tnttYuba21aaxvGc8fy99bCH7jdnckeVuSPZM8e522DQAwN2Z5wccPVtXzquq3xvJhK7Q9ciw/vMyyDy1pAwDABNP62nd3/NT4+idVdVaSY1prX1xUt1eSH0pyQ2vtqmXWc+lYPnAtG62q8ycsWst5igAAW9osjvzdlOR3kmxLcp/xtXCe4BFJPjoGvgX7jOV1E9a3UH/vaQ8UAGDebPiRv9ba1Ules6T6nKp6QpKPJTk4yXOSvHlXV73G7W9brn48IvjIXdwmAMCWsmlu8txauzXJu8a3hy1atHBkb58sb7UjgwAAjDZN+Bt9bSz/6Wvf1tqNSb6c5Puq6gHL9DlwLC9Z57EBAGx5my38PWYsL19Sf8ZYPnGZPk9a0gYAgAk2PPxV1cFVdfdl6o/McLPoJFn6aLh3jOUrq+o+i/rsl+QFSW5J8u7pjxYAYL5M5YKPqjoqyVHj2/uP5SFVdeL48zWttZeNP78uyUPG27pcOdY9LHfcp+/VrbXzFq+/tXZeVb0hya8luaiqTs3weLdfSLJvkhd6ugcAwOqmdbXvI5Ics6TugPGVJF9IshD+3pvkqUkeleEr27sl+WqS9yV5a2vt3OU20Fp7aVVdlORXk/xKktuTXJDk9a21v57SfgAAzLWphL/xGb3b19j2hCQn7OZ23pPkPbvTFwCAzXfBBwAA60j4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOTCX8VdXRVfWWqjq3qq6vqlZVJ01oe2BVvbyqzqiqL1XVd6rqq1X1gap63IQ+zxrXOen1/GnsBwDAvNtjSut5VZKHJ7khyZVJHrxC299J8gtJ/j7J6UmuTfKgJE9J8pSqenFr7Y8m9P1AkguXqf/07g0bAKAv0wp/L8kQ+i5LcniSM1do++Ekr2ut/a/FlVV1eJK/TfL6qjqltXbVMn1Pa62dOJ0hAwD0Zypf+7bWzmytXdpaa2toe+LS4DfWn53krCR3T3LoNMYFAMD3mtaRv2n57ljeOmH5I6rq2CT3SPLlJGe21q7ciIEBAMyDTRP+quqHkzw+yU1JzpnQ7MVL3t9WVe9Kcmxr7dvrOT4AgHmwKcJfVe2Z5M+T7JnkN1pr31jS5IokL0zykQznFu6T5CeS/H6S5yXZO8kvrnFb509YtNJFKgAAc2Hm9/mrqrsmeW+Sxyb5iyTHL23TWju7tfbW1tolrbWbWmtXtdZOSfK4JN9I8u+r6uEbOnAAgC1opkf+xuB3UpKnJXlfkmes5aKRBa21L1XV6Ul+KclhST6zhj7bJozl/CSPXOu2AQC2opkd+auqPZL8tyRPT/Jfk/xia23ShR4r+dpY7jWtsQEAzKuZHPmrqrtnONL3s0n+LMmzW2u37+bqDh7Ly6cxNgCAebbhR/7GizvenyH4nZA1BL+q+sll6qqqfjPJIUmuyXDzaAAAVjCVI39VdVSSo8a39x/LQ6rqxPHna1prLxt/fkeSn84Q2L6c5DVVtXSVZ7XWzlr0/pyquiTJp8Y++2S4QOShGW4N80utteunsS8AAPNsWl/7PiLJMUvqDhhfSfKFJAvhb/+x/GdJXrPCOs9a9PPxSR6d5Mgk+ya5PckXk7wtyRtaa77yBQBYg6mEv9ba9iTb19j2iN1Y/6/vah8AAHY28/v8AQCwcYQ/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0JGphL+qOrqq3lJV51bV9VXVquqkVfocWlWnV9W1VXVTVV1UVcdW1V1X6HNMVX2yqm6oquuq6qyq+plp7AMAQA+mdeTvVUl+Nckjknx5tcZV9bNJzklyWJL3J3lbkrsneWOSkyf0OT7JiUkekOSdSU5K8qNJ/qqqfvXO7gAAQA+mFf5ekuSBSfZO8p9WalhVe2cIb7clOaK19suttV/PEBw/keToqnr6kj6HJnlpks8neVhr7SWttRck2Zbk2iTHV9V+U9oXAIC5NZXw11o7s7V2aWutraH50Unul+Tk1tqnF63j2xmOICY7B8jnj+Xvtda+sajPjgxHDfdM8uzdHD4AQDdmccHHkWP54WWWnZPkpiSHVtWea+zzoSVtAACYYI8ZbPNBY3nJ0gWttVur6ookD0lyQJKLq2qvJD+U5IbW2lXLrO/SsXzgWjZeVedPWPTgtfQHANjKZnHkb5+xvG7C8oX6e+9mewAAJpjFkb/V1Fiu5fzBxdbUvrW2bdmNDkcEH7mL2wQA2FJmceRv4UjdPhOW772k3WrtVzsyCADAaBbh73NjudM5elW1R5L9k9ya5PIkaa3dmOHegd9XVQ9YZn0HjuVO5xACAPC9ZhH+zhjLJy6z7LAk90pyXmvtljX2edKSNgAATDCL8HdqkmuSPL2qfnyhsqrukeR3x7dvX9LnHWP5yqq6z6I++yV5QZJbkrx7vQYMADAvpnLBR1UdleSo8e39x/KQqjpx/Pma1trLkqS1dn1VPTdDCDyrqk7O8JSOp2S4DcypSf5i8fpba+dV1RuS/FqSi6rq1AyPg/uFJPsmeeF4w2cAAFYwrat9H5HkmCV1B4yvJPlCkpctLGitnVZVhyd5ZZKfS3KPJJdlCHd/tNyTQlprL62qizI8Q/hXktye5IIkr2+t/fWU9gMAYK5NJfy11rYn2b6LfT6e5Kd3sc97krxnV/oAAHCHWZzzBwDAjAh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANCRmYS/qnpWVbVVXrctar/fKm1PnsV+AABsNXvMaLsXJnnthGU/meTIJB9aZtlnkpy2TP1npzIqAIA5N5Pw11q7MEMA3ElVfWL88U+WWXxha237+owKAGD+bapz/qrqoUkek+TLST444+EAAMydWX3tO8nzxvKE1tptyyz/wap6XpL7Jvl6kk+01i7asNEBAGxxmyb8VdU9kzwjye1J3jWh2U+Nr8X9zkpyTGvti2vczvkTFj14bSMFANi6NtPXvj+f5N5JPtRa+9KSZTcl+Z0k25LcZ3wdnuTMJEck+WhV7bVhIwUA2KI2zZG/JL8yln+8dEFr7eokr1lSfU5VPSHJx5IcnOQ5Sd682kZaa9uWqx+PCD5yVwYMALDVbIojf1X1b5IcmuTKJKevtV9r7dbc8RXxYeswNACAubIpwl9Wv9BjJV8bS1/7AgCsYubhr6rukeSZGS70OGE3VvGYsbx8aoMCAJhTMw9/SZ6W4QKO05e50CNJUlUHV9Xdl6k/MslLxrcnrd8QAQDmw2a44GPhQo/lnuix4HVJHjLe1uXKse5hGR4DlySvbq2dtz7DAwCYHzMNf1V1UJKfyOoXerw3yVOTPCrJk5LcLclXk7wvyVtba+eu81ABAObCTMNfa+3iJLWGdidk984HBABgkc1wzh8AABtE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjsws/FXVjqpqE15fmdDn0Ko6vaquraqbquqiqjq2qu660eMHANiK9pjx9q9L8qZl6m9YWlFVP5vkL5N8O8lfJLk2yb9L8sYkj03ytHUbJQDAnJh1+Ptma237ao2qau8k70xyW5IjWmufHutfneSMJEdX1dNbayev52ABALa6rXLO39FJ7pfk5IXglySttW8nedX49j/NYmAAAFvJrI/87VlVz0jyr5LcmOSiJOe01m5b0u7IsfzwMus4J8lNSQ6tqj1ba7es22gBALa4WYe/+yd575K6K6rq2a21sxfVPWgsL1m6gtbarVV1RZKHJDkgycUrbbCqzp+w6MFrGzIAwNY1y699353k8RkC4F5JfjTJHyfZL8mHqurhi9ruM5bXTVjXQv29pz5KAIA5MrMjf6211y6p+myS51fVDUlemmR7kqeucXW1sNo1bHfbsisYjgg+co3bAwDYkjbjBR/vGMvDFtUtHNnbJ8vbe0k7AACWsRnD39Vjudeius+N5QOXNq6qPZLsn+TWJJev79AAALa2zRj+DhnLxUHujLF84jLtD0tyryTnudIXAGBlMwl/VfWQqtp3mfofTvLW8e1JixadmuSaJE+vqh9f1P4eSX53fPv2dRouAMDcmNUFH09L8oqqOjPJFUm+leRHkjw5yT2SnJ7k+IXGrbXrq+q5GULgWVV1cobHuz0lw21gTs3wyDcAAFYwq/B3ZobQ9mMZvubdK8k3k3wsw33/3tta+54rd1trp1XV4UlemeTnMoTEy5L8WpI/WtoeAICdzST8jTdwPnvVhjv3+3iSn57+iAAA+rAZL/gAAGCdCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEf2mPUA2Lr2e8UHZz2Eqdhx3JNnPQQA2DCO/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHZhL+quq+VfWcqnp/VV1WVTdX1XVV9bGq+uWqusuS9vtVVVvhdfIs9gMAYKvZY0bbfVqStye5KsmZSb6Y5J8n+b+TvCvJk6rqaa21tqTfZ5Kctsz6Prt+QwUAmB+zCn+XJHlKkg+21m5fqKyq30ryySQ/lyEI/uWSfhe21rZv1CABAObNTL72ba2d0Vr7q8XBb6z/SpJ3jG+P2PCBAQDMuVkd+VvJd8fy1mWW/WBVPS/JfZN8PcknWmsXbdjImEv7veKDsx7C1Ow47smzHgIAm9ymCn9VtUeS/zC+/fAyTX5qfC3uc1aSY1prX1zjNs6fsOjBaxwmAMCWtdlu9XJckocmOb219jeL6m9K8jtJtiW5z/g6PMPFIkck+WhV7bWxQwUA2Ho2zZG/qnpRkpcm+Yckz1y8rLV2dZLXLOlyTlU9IcnHkhyc5DlJ3rzadlpr2yZs//wkj9z1kQMAbB2b4shfVb0gQ3D7+ySPa61du5Z+rbVbM9waJkkOW6fhAQDMjZmHv6o6NslbM9yr73HjFb+74mtj6WtfAIBVzDT8VdXLk7wxyYUZgt/Vu7Gax4zl5dMaFwDAvJpZ+KuqV2e4wOP8JI9vrV2zQtuDq+ruy9QfmeQl49uT1mWgAABzZCYXfFTVMUl+O8ltSc5N8qKqWtpsR2vtxPHn1yV5yHhblyvHuoclOXL8+dWttfPWc8wAAPNgVlf77j+Wd01y7IQ2Zyc5cfz5vUmemuRRSZ6U5G5JvprkfUne2lo7d70GCgAwT2YS/sbn827fhfYnJDlhvcYDANCLmV/tCwDAxhH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRkj1kPAICtYb9XfHDWQ5iaHcc9edZDgJlx5A8AoCPCHwBAR3ztC3PE13IArMaRPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiKt9AdbZPF2FDWx9jvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdcZ8/YFNybzzW0zz9+9px3JNnPQS2GEf+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjrjPHwBsYfN0z8J5sdnvvejIHwBAR4Q/AICObKnwV1X/oqr+tKr+sapuqaodVfWmqrrPrMcGALAVbJlz/qrqR5Kcl+QHknwgyT8keXSSFyd5YlU9trX29RkOEQBg09tKR/7+3wzB70WttaNaa69orR2Z5I1JHpTk92Y6OgCALWBLhL+qOiDJE5LsSPK2JYv/c5Ibkzyzqvba4KEBAGwpWyL8JTlyLD/SWrt98YLW2reSfDzJvZI8ZqMHBgCwlWyVc/4eNJaXTFh+aYYjgw9M8tGVVlRV509Y9PCLL74427Zt270RrtFVX75uXdcPAMzWtr99zbpv4+KLL06S/Xan71YJf/uM5aTktFB/7zuxjdtuvvnm6y644IIdd2Idq3nwWP7DOm5jqzEnOzMnOzMnOzMnOzMnOzMnO1v3Obngq+u15u+xX5Lrd6fjVgl/q6mxbKs1bK2t76G9FSwcdZzlGDYbc7Izc7Izc7Izc7Izc7Izc7Izc7J1zvlbOLK3z4Tley9pBwDAMrZK+PvcWD5wwvIDx3LSOYEAAGTrhL8zx/IJVfU9Y66q70/y2CQ3J/m7jR4YAMBWsiXCX2vt80k+kuHkxhcsWfzaJHsl+bPW2o0bPDQAgC1lK13w8f9keLzbH1XV45NcnOTgJI/L8HXvK2c4NgCALaFaW/UC2U2jqv5lkt9O8sQk901yVZLTkry2tXbtDIcGALAlbKnwBwDAnbMlzvkDAGA6hD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwtwGq6l9U1Z9W1T9W1S1VtaOq3lRV95n12O6MqrpvVT2nqt5fVZdV1c1VdV1Vfayqfnnpo/gW9Tu0qk6vqmur6qaquqiqjq2qu66wrWOq6pNVdcO4jbOq6mfWb++mq6qeWVVtfD1nQpu5n5eq+smq+suqumr8Xbiqqj5SVT+9TNse5uPJ4/5fOf7+XF5Vp1TVIRPaz8WcVNXRVfWWqjq3qq4ffy9OWqXPuu97Vd2zql5bVZ+rqm9X1dVV9b6qOujO7O9a7MqcVNWBVfXyqjqjqr5UVd+pqq9W1Qeq6nGrbGcu52RC/xMWfe7+6xXabZk5mZrWmtc6vpL8SJKvJmkZbkh9XJIzxvf/kOS+sx7jndi354/78Y9J/jzJ7yf50yTfHOtPzXgvyUV9fjbJrUluSHJCkteP89CSnDJhO8ePy7+U5I1J3pbk62Pdr856HtYwT/9ynJNvjWN+zjJt5n5ekrxqHNvXkrw7yX9J8idJPpXkDzqcj9eNY7smybvGz4ZTk3wnye1JnjGvc5LkwnEM38rwtKaW5KQV2q/7vifZM8nHxuWfGv/7/Nck301yY5KDN8ucJDl5XP6/k/xxhs/e/z7OUUvyot7mZJm+/25R35bkX8/DnExtbmc9gHl/Jfmb8R/JC5fUv2Gsf8esx3gn9u3I8RfsLkvq75/ki+P+/dyi+r2TXJ3kliQ/vqj+Hhke3deSPH3Jug4d6y9Lcp9F9fuNv6DfTrLfrOdihTmqJP8jyecz/A9rp/DXw7wkedo43r9N8v3LLL9bZ/Nx/yS3JflKkh9Ysuxx475cPq9zMu7jgePvxxFZOehsyL4n+c2xzylZ9JmWIXguBK273Jn9nuKcPCvJjy1Tf3iGPx5uSfKAnuZkSb/7jb9bJyc5KxPC31ack6nN7awHMM+vJAeM/xiuWPqPIcn3Z/gr9sYke816rOuw77817vtbFtX9x7HuPcu0P3JcdvaS+j8b65+9TJ/fHpe9dtb7u8I8vDjDUZzDkmzP8uFvruclw+kll4//1u+3hvZzPR/jmA4ex/SBCcuvT/KtHuYkqweddd/3DOHiC2P9/sv0OWdc9rjNMCer9P1Ilvzh3ducJHl/hvB336wc/rb0nNyZl3P+1teRY/mR1trtixe01r6V5ONJ7pXkMRs9sA3w3bG8dVHdwnx8eJn25yS5KcmhVbXnGvt8aEmbTWU8/+O4JG9urZ2zQtN5n5dDk+yf5PQk3xjPc3t5Vb14wrlt8z4fSXJphiM0j66qf7Z4QVUdluGPw/+xqLqHOZlkI/b9R5L8qySXtNauWGOfzWq5z96kkzmpqmclOSrJ81trX1+leRdzshzhb309aCwvmbD80rF84AaMZcNU1R5J/sP4dvEv1cT5aK3dmuEI6R4ZjpimqvZK8kNJbmitXbXMpjbt/I1z8N4MX3//1irN531eHjWWX01yQZK/zhCK35TkvKo6u6rut6j9vM9HWmvXJnl5kn+e5O+r6k+q6ver6n0Zjtz8bZLnLeoy93Oygo3Y97n4rK6qH07y+AyB+JxF9V3Mybj/b85wdPC0Vdp2MSeT7DHrAcy5fcbyugnLF+rvvf5D2VDHJXloktNba3+zqH5X52Mrz99rkvxYkp9ord28Stt5n5cfGMvnZ/gf9b9N8j+T/HCSP0zyf2U4f+aIsd28z0eSpLX2pqrakeEiqecuWnRZkhNba1cvqutiTibYiH3f8vM1Hvn88wwXJPxGa+0bixbP/ZzUcHeJ92Q4nepFa+gy93OyEkf+ZqvGss10FFNUVS9K8tIMV+I9c1e7j+Wuzsemmr+qenSGo31/2Fr7xDRWOZZbdV4WbsVRSY5urX20tXZDa+1/J3lqkiuTHD7hK+DlbPX5SJJU1W9kuLr3xAxfJ+2VZFuG8yP/vKr+YFdWN5Zbek5200bs+6b+rB5vd/PeJI9N8hcZrmDdHVt5Tl6S4YKX5y4JvnfWVp6TiYS/9bXwV8A+E5bvvaTdllZVL8hwyP3vM5zweu2SJrs6H6u1X+2vsA236OveS5K8eo3d5n1eFj6IL2+tfWbxgvGo6MLR4UeP5bzPR6rqiAy3iPj/Wmu/1lq7vLV2U2vtggyB+MtJXlpVB4xd5n5OVrAR+75lP6vH4HdShivq35fhFkFLw8dcz0lVHZjk95K8u7V2+hq7zfWcrEb4W1+fG8tJ3/8fOJaTzh/YMqrq2CRvTfLZDMHvK8s0mzgfY2jaP8NJypcnSWvtxgz/E/y+qnrAMuvbjPP3fRn276Ak3150g9GW5D+Pbd451r1pfD/v87Kwf9+csHwhHN5zSft5nY8kWbiB7JlLF7TWbkryyQyfzz82VvcwJ5NsxL5vyc/qcf//W5KnZ7jX3C+O50F+jw7m5CEZvu5+9uLP3PFz9/CxzaVj3VFJF3OyIuFvfS18sD+hljztoqq+P8Mh+puT/N1GD2yaqurlGW6OeWGG4Hf1hKZnjOUTl1l2WIYrn89rrd2yxj5PWtJmM7glw01ol3v9r7HNx8b3C18Jz/u8nJPhf84HVtXdl1n+0LHcMZbzPh/J8D+qZLgf2XIW6r8zlj3MySQbse+fz3Bx1gOrav819pmp8Xfp1AxH/P4syTNba7et0GWe52RHJn/uLhyIOGV8v2NRv3mek5XN+l4z8/7KHN/kedyPV4/78ekk+67Sdu8MT3eYixvV7sZcbc/kmzzP9bxk+FqqJfndJfU/leE+iN9Mcu+O5uPnx/F+JckPLVn2pHFObs74BKB5npOs7SbP677v2UQ3713DnOyZ5INjm3etZVzzPicr9DsrbvK887zMegDz/srOj3f7/dzxeLfPZWs/3u2YcT9uzXDkb/syr2ct6XNU7nhM07uS/EEWPaYpSx4HN/b5w3H54sfvXDPWbbrHdq0wX9uzTPjrYV4yXPF76Ti2czKckH7KuM/fTfK0zubjLhlu59Iy3ND5PRnPAcwQ/FqSF8/rnIz7cuL4+vA4ns8vqjt+o/c9Q6D6+Lj8UxnuWrCRjzJb85xkeDxiyxCKX5vlP3uP6GlOVljHWZkQ/rbinExtbmc9gB5eGZ7t+u4kV2X4GucLGS6MWPFI2WZ/5Y4ws9LrrGX6PTbjDX8zHN34/zNcqXXXFbZ1zPiLdmOGZzWeneRnZj0HuzlfO4W/HuYlyb4ZjnhfMf4efD3JB5I8ptP5uFuSYzOc9nF9hnBzdYb7ID5hnudkDZ8dO2ax7xnOO31thj9UbskQrk5J8m8205zkjkCz0mt7T3OywjoW5mrZ8LfV5mRarxp3BACADrjgAwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCP/B0lxAz4HKGbRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ayush\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128,return_sequences=True))\n",
    "  model.add(LSTM(128))\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dense(n_vocab))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           16700     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 167)               42919     \n",
      "=================================================================\n",
      "Total params: 267,939\n",
      "Trainable params: 267,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 4.3536\n",
      "Epoch 00001: val_loss improved from inf to 4.13264, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 35ms/step - loss: 4.3522 - val_loss: 4.1326\n",
      "Epoch 2/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 3.8015\n",
      "Epoch 00002: val_loss improved from 4.13264 to 3.80355, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 35ms/step - loss: 3.8015 - val_loss: 3.8035\n",
      "Epoch 3/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 3.6113\n",
      "Epoch 00003: val_loss improved from 3.80355 to 3.65502, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 3.6111 - val_loss: 3.6550\n",
      "Epoch 4/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 3.4714\n",
      "Epoch 00004: val_loss improved from 3.65502 to 3.59723, saving model to best_model.h5\n",
      "403/403 [==============================] - 13s 33ms/step - loss: 3.4714 - val_loss: 3.5972\n",
      "Epoch 5/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 3.3688\n",
      "Epoch 00005: val_loss improved from 3.59723 to 3.50182, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 3.3686 - val_loss: 3.5018\n",
      "Epoch 6/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 3.2882\n",
      "Epoch 00006: val_loss improved from 3.50182 to 3.42948, saving model to best_model.h5\n",
      "403/403 [==============================] - 13s 33ms/step - loss: 3.2880 - val_loss: 3.4295\n",
      "Epoch 7/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 3.2105\n",
      "Epoch 00007: val_loss improved from 3.42948 to 3.34378, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 3.2103 - val_loss: 3.3438\n",
      "Epoch 8/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 3.1486\n",
      "Epoch 00008: val_loss improved from 3.34378 to 3.33535, saving model to best_model.h5\n",
      "403/403 [==============================] - 13s 33ms/step - loss: 3.1485 - val_loss: 3.3354\n",
      "Epoch 9/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 3.0881\n",
      "Epoch 00009: val_loss improved from 3.33535 to 3.28003, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 3.0879 - val_loss: 3.2800\n",
      "Epoch 10/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 3.0361\n",
      "Epoch 00010: val_loss improved from 3.28003 to 3.26507, saving model to best_model.h5\n",
      "403/403 [==============================] - 13s 33ms/step - loss: 3.0356 - val_loss: 3.2651\n",
      "Epoch 11/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.9928\n",
      "Epoch 00011: val_loss improved from 3.26507 to 3.20910, saving model to best_model.h5\n",
      "403/403 [==============================] - 13s 33ms/step - loss: 2.9928 - val_loss: 3.2091\n",
      "Epoch 12/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.9437\n",
      "Epoch 00012: val_loss improved from 3.20910 to 3.17720, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.9437 - val_loss: 3.1772\n",
      "Epoch 13/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.9025\n",
      "Epoch 00013: val_loss improved from 3.17720 to 3.13544, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.9026 - val_loss: 3.1354\n",
      "Epoch 14/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.8692\n",
      "Epoch 00014: val_loss improved from 3.13544 to 3.13416, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.8692 - val_loss: 3.1342\n",
      "Epoch 15/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 2.8285\n",
      "Epoch 00015: val_loss improved from 3.13416 to 3.10114, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 35ms/step - loss: 2.8284 - val_loss: 3.1011\n",
      "Epoch 16/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.8020\n",
      "Epoch 00016: val_loss improved from 3.10114 to 3.07172, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 35ms/step - loss: 2.8020 - val_loss: 3.0717\n",
      "Epoch 17/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.7698\n",
      "Epoch 00017: val_loss improved from 3.07172 to 3.07017, saving model to best_model.h5\n",
      "403/403 [==============================] - 17s 41ms/step - loss: 2.7698 - val_loss: 3.0702\n",
      "Epoch 18/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.7393\n",
      "Epoch 00018: val_loss improved from 3.07017 to 3.04203, saving model to best_model.h5\n",
      "403/403 [==============================] - 15s 36ms/step - loss: 2.7394 - val_loss: 3.0420\n",
      "Epoch 19/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.7139\n",
      "Epoch 00019: val_loss improved from 3.04203 to 3.01687, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.7139 - val_loss: 3.0169\n",
      "Epoch 20/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 2.6854\n",
      "Epoch 00020: val_loss improved from 3.01687 to 2.99305, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.6858 - val_loss: 2.9930\n",
      "Epoch 21/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.6683\n",
      "Epoch 00021: val_loss improved from 2.99305 to 2.98108, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.6677 - val_loss: 2.9811\n",
      "Epoch 22/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.6485\n",
      "Epoch 00022: val_loss improved from 2.98108 to 2.97079, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.6496 - val_loss: 2.9708\n",
      "Epoch 23/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.6298\n",
      "Epoch 00023: val_loss did not improve from 2.97079\n",
      "403/403 [==============================] - 13s 33ms/step - loss: 2.6304 - val_loss: 2.9761\n",
      "Epoch 24/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.5953\n",
      "Epoch 00024: val_loss improved from 2.97079 to 2.94480, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.5958 - val_loss: 2.9448\n",
      "Epoch 25/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.5808\n",
      "Epoch 00025: val_loss improved from 2.94480 to 2.92553, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.5808 - val_loss: 2.9255\n",
      "Epoch 26/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.5729\n",
      "Epoch 00026: val_loss improved from 2.92553 to 2.91365, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.5729 - val_loss: 2.9136\n",
      "Epoch 27/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.5566\n",
      "Epoch 00027: val_loss did not improve from 2.91365\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.5566 - val_loss: 2.9182\n",
      "Epoch 28/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.5409\n",
      "Epoch 00028: val_loss improved from 2.91365 to 2.90214, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.5409 - val_loss: 2.9021\n",
      "Epoch 29/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.5279\n",
      "Epoch 00029: val_loss did not improve from 2.90214\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.5283 - val_loss: 2.9071\n",
      "Epoch 30/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 2.5112\n",
      "Epoch 00030: val_loss improved from 2.90214 to 2.89002, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.5119 - val_loss: 2.8900\n",
      "Epoch 31/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.5023\n",
      "Epoch 00031: val_loss improved from 2.89002 to 2.87961, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.5024 - val_loss: 2.8796\n",
      "Epoch 32/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 2.4917\n",
      "Epoch 00032: val_loss improved from 2.87961 to 2.86894, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.4916 - val_loss: 2.8689\n",
      "Epoch 33/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.4719- ETA: 0s - loss: 2.472\n",
      "Epoch 00033: val_loss improved from 2.86894 to 2.84629, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.4721 - val_loss: 2.8463\n",
      "Epoch 34/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 2.4595\n",
      "Epoch 00034: val_loss did not improve from 2.84629\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.4602 - val_loss: 2.8724\n",
      "Epoch 35/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.4542\n",
      "Epoch 00035: val_loss improved from 2.84629 to 2.84545, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.4542 - val_loss: 2.8455\n",
      "Epoch 36/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.4366\n",
      "Epoch 00036: val_loss improved from 2.84545 to 2.84337, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.4366 - val_loss: 2.8434\n",
      "Epoch 37/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.4339\n",
      "Epoch 00037: val_loss improved from 2.84337 to 2.83027, saving model to best_model.h5\n",
      "403/403 [==============================] - 15s 37ms/step - loss: 2.4339 - val_loss: 2.8303\n",
      "Epoch 38/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.4182\n",
      "Epoch 00038: val_loss improved from 2.83027 to 2.82594, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 36ms/step - loss: 2.4182 - val_loss: 2.8259\n",
      "Epoch 39/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 2.4166\n",
      "Epoch 00039: val_loss improved from 2.82594 to 2.82430, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.4167 - val_loss: 2.8243\n",
      "Epoch 40/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.4053\n",
      "Epoch 00040: val_loss improved from 2.82430 to 2.81822, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.4059 - val_loss: 2.8182\n",
      "Epoch 41/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.4027\n",
      "Epoch 00041: val_loss improved from 2.81822 to 2.81139, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.4027 - val_loss: 2.8114\n",
      "Epoch 42/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 2.3841\n",
      "Epoch 00042: val_loss improved from 2.81139 to 2.80368, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.3843 - val_loss: 2.8037\n",
      "Epoch 43/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.3705\n",
      "Epoch 00043: val_loss improved from 2.80368 to 2.78760, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 35ms/step - loss: 2.3705 - val_loss: 2.7876\n",
      "Epoch 44/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.3641\n",
      "Epoch 00044: val_loss did not improve from 2.78760\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.3641 - val_loss: 2.7890\n",
      "Epoch 45/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.3674\n",
      "Epoch 00045: val_loss improved from 2.78760 to 2.78088, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.3674 - val_loss: 2.7809\n",
      "Epoch 46/50\n",
      "401/403 [============================>.] - ETA: 0s - loss: 2.3588\n",
      "Epoch 00046: val_loss did not improve from 2.78088\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.3590 - val_loss: 2.7814\n",
      "Epoch 47/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.3453\n",
      "Epoch 00047: val_loss improved from 2.78088 to 2.77298, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.3453 - val_loss: 2.7730\n",
      "Epoch 48/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.3374- ETA: 0s - lo\n",
      "Epoch 00048: val_loss did not improve from 2.77298\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.3374 - val_loss: 2.7746\n",
      "Epoch 49/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.3278\n",
      "Epoch 00049: val_loss improved from 2.77298 to 2.76882, saving model to best_model.h5\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.3278 - val_loss: 2.7688\n",
      "Epoch 50/50\n",
      "402/403 [============================>.] - ETA: 0s - loss: 2.3315\n",
      "Epoch 00050: val_loss did not improve from 2.76882\n",
      "403/403 [==============================] - 14s 34ms/step - loss: 2.3318 - val_loss: 2.7716\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 161, 57, 161, 57, 135, 105, 135, 135, 135]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
